NOTE
    * understand the difference between prediction and explanation

Building Machines That Think and Learn Like People
    - the importance of physical scene understanding to intelligence
    - Essential components of human intelligence
        - ``people can learn models and use them for arbitrary new goals and tasks with little or no retraining or reconfiguration.''
            - Context for your generalization argument: say that it is because of the model's causality and compositionality and structure that allows it to do so (evidenced by comparison to the baseline)
        - What you learn and how you learn it
            - If your goal is scene understanding then
                - what you learn: dynamics of the physical scenes and object properties that make it so
                - how you learn it: learning a simulator. you also want your learning process to be scalalbe
        - 1. Build causal models of the world that support explanation and understanding
            - can my model EXPLAIN things?
            - a simulator naturally is causal <-- argument for learning a simulator
        - 2. Ground learning intuitive theories of physics and psychology, to support and enrich the knowledge that is learned
            - well this comment can be in the disucssion because my model is attempting to ground things in intuitive theories of physics, and that this can ``support'' and ``enrich'' knowledge that has been learned because it is a simulator and can be used as a primitive in a higher level system.
    - why is human-like intellgience desirable?
        - it's because it allows us to do explain rather than just pattern match. We explain using a model.
        - human intelligence can help INFORM and advance AI because ``natural intellgence remains the best example of intelligence''
    - Cognition and thought is about using these models to understand the world, explain what we see, imagine what could have happened that didn’t, what could be true that isn’t, and then planning actions to make it so. The difference between pattern recognition and model-building, between prediction and explanation, is central to our view of human intelligence.
        - Hmmm, is my model model-building though?  --> This will be tricky to profess
        - My model is doing prediction. Does it do any explaining? What does explaining mean?
            - Well one example of strong explanation is inferring the EXISTENCE of an unknown latent property (global parameters)
            - A weaker form of explanation is to inferring the IDENTITY/NATURE of a KNOWN latent property (local parameters)
        - A simulator can ``imagine what could have happened that didn’t, what could be true that isn’t''
        - the process of building that simulator is the process of MODEL BUILDING
    - Does learning to learn apply here? "TODO"
    - How to automate model building: Exploiting compositionality to explore a large space of model structures. "READ"


Simulation as an Engine for Physical Scene Understanding
    - the importance of simulation


Billiard Balls


Learning Physics from Dynamical Scenes


Kevin Ellis
    - sketch



RNN Disadvantages
    - locked into particular input output patterns
    - representations hard to reuse


